"""
ì—”ì¹´(encar.com) ì¤‘ê³ ì°¨ ê°€ê²© ì •ë³´ í¬ë¡¤ëŸ¬
"""
import re
import time
import logging
import pandas as pd
from datetime import datetime
import sys
import os
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from database.db_helper import db_helper

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class EncarCrawler:
    def __init__(self, config):
        """í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì‹œ ì„¤ì •(config)ì„ ì „ë‹¬ë°›ìŒ"""
        self.config = config
        self.driver = None
        
    def setup_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì„¤ì •"""
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        
        try:
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            logger.info("âœ… Chrome ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ Chrome ë“œë¼ì´ë²„ ì„¤ì • ì‹¤íŒ¨: {e}")
            raise
            
    def close_driver(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            logger.info("ë“œë¼ì´ë²„ ì¢…ë£Œ ì™„ë£Œ")
            
    def search_car_prices(self, manufacturer, model_name, year=None):
        """íŠ¹ì • ì°¨ëŸ‰ì˜ ê°€ê²© ì •ë³´ ê²€ìƒ‰"""
        try:
            if not self.driver:
                self.setup_driver()
                
            search_query = f"{manufacturer} {model_name}"
            if year:
                search_query += f" {year}"
            
            # ì„¤ì •ì—ì„œ URLê³¼ ë”œë ˆì´ ê°’ ì‚¬ìš©
            search_url = self.config.get('search_url', 'http://www.encar.com/dc/dc_carsearchlist.do')
            delay = self.config.get('delay', 2)
            url = f"{search_url}?q={search_query}"
            
            logger.info(f"ğŸ” ê²€ìƒ‰ ì¤‘: {search_query}")
            self.driver.get(url)
            time.sleep(delay)
            
            page_source = self.driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            
            car_data = self._parse_car_listings(soup, manufacturer, model_name, year)
            return car_data
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
            
    def _parse_car_listings(self, soup, manufacturer, model_name, year):
        """ì°¨ëŸ‰ ëª©ë¡ íŒŒì‹± (ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)"""
        car_data = []
        try:
            listings = soup.select('.car-item, .lst-wrap, .area')
            max_items = self.config.get('max_items_per_model', 20) # ì„¤ì •ì—ì„œ ìµœëŒ€ ì•„ì´í…œ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
            
            for listing in listings[:max_items]:
                try:
                    price_elem = listing.select_one('.price, .pri, .cost')
                    if not price_elem:
                        continue
                    
                    price = self._extract_price(price_elem.text)
                    year_from_page = self._extract_year(listing.select_one('.year, .inf, .detail').text) if listing.select_one('.year, .inf, .detail') else None
                    mileage_elem = listing.select_one('.mileage, .km, .distance')
                    mileage = self._extract_mileage(mileage_elem.text) if mileage_elem else 0
                    
                    car_data.append({
                        'manufacturer': manufacturer,
                        'model_name': model_name,
                        'year': year or year_from_page,
                        'price': price,
                        'mileage_range': self._get_mileage_range(mileage),
                        'source': 'encar',
                        'collected_date': datetime.now().date()
                    })
                except Exception as e:
                    logger.debug(f"ê°œë³„ í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            logger.info(f"âœ… {len(car_data)}ê°œ ì°¨ëŸ‰ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return car_data
        
    def _extract_price(self, text):
        numbers = re.findall(r'[\d,]+', text)
        return int(numbers[0].replace(',', '')) if numbers else 0
        
    def _extract_year(self, text):
        year_match = re.search(r'(20\d{2})|(\d{2}ë…„)', text)
        if year_match:
            if year_match.group(1):
                return int(year_match.group(1))
            if year_match.group(2):
                return 2000 + int(year_match.group(2)[:2])
        return None
        
    def _extract_mileage(self, text):
        numbers = re.findall(r'[\d,]+', text)
        if numbers:
            mileage = int(numbers[0].replace(',', ''))
            return mileage * 10000 if 'ë§Œ' in text else mileage
        return 0
        
    def _get_mileage_range(self, mileage):
        if mileage == 0: return 'ì•Œìˆ˜ì—†ìŒ'
        elif mileage < 30000: return '3ë§Œkm ë¯¸ë§Œ'
        elif mileage < 50000: return '3-5ë§Œkm'
        elif mileage < 70000: return '5-7ë§Œkm'
        elif mileage < 100000: return '7-10ë§Œkm'
        elif mileage < 150000: return '10-15ë§Œkm'
        else: return '15ë§Œkm ì´ìƒ'
            
    def crawl_and_save(self, car_list):
        """ì°¨ëŸ‰ ëª©ë¡ì„ í¬ë¡¤ë§í•˜ê³  DBì— ì €ì¥"""
        db_helper.update_crawling_log('encar', 'ì‹œì‘')
        total_collected = 0
        delay = self.config.get('delay', 2)
        
        try:
            for car in car_list:
                model_id = db_helper.get_or_insert_car_model(car['manufacturer'], car['model_name'])
                car_data = self.search_car_prices(car['manufacturer'], car['model_name'], car.get('year'))
                
                if car_data:
                    df = pd.DataFrame(car_data)
                    grouped = df.groupby(['year', 'mileage_range'])['price'].agg(
                        avg_price=('mean'), min_price=('min'),
                        max_price=('max'), sample_count=('count')
                    ).reset_index()
                    
                    for _, row in grouped.iterrows():
                        db_helper.insert_used_car_price(
                            model_id=model_id, year=int(row['year']) if pd.notna(row['year']) else None,
                            mileage_range=row['mileage_range'], avg_price=float(row['avg_price']),
                            min_price=float(row['min_price']), max_price=float(row['max_price']),
                            sample_count=int(row['sample_count']), data_source='encar'
                        )
                    total_collected += len(car_data)
                    logger.info(f"âœ… {car['model_name']} ë°ì´í„° ì €ì¥ ì™„ë£Œ ({len(car_data)}ê±´)")
                time.sleep(delay)
                
            db_helper.update_crawling_log('encar', 'ì™„ë£Œ', total_collected)
            logger.info(f"ğŸ‰ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ! ì´ {total_collected}ê±´ ìˆ˜ì§‘")
        except Exception as e:
            db_helper.update_crawling_log('encar', 'ì‹¤íŒ¨', total_collected, str(e))
            logger.error(f"í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        finally:
            self.close_driver()

if __name__ == '__main__':
    import json
    print("í¬ë¡¤ëŸ¬ ë‹¨ë… í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    
    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì„¤ì • íŒŒì¼ì„ ì§ì ‘ ë¡œë“œ
    try:
        with open('config/scheduler_config.json', 'r', encoding='utf-8') as f:
            full_config = json.load(f)
        encar_config = full_config['crawling']['encar']
        print("âœ… í…ŒìŠ¤íŠ¸ ì„¤ì • ë¡œë“œ ì™„ë£Œ")
        
        crawler = EncarCrawler(config=encar_config)
        
        test_cars = [
            {'manufacturer': 'í˜„ëŒ€', 'model_name': 'ê·¸ëœì € IG'},
            {'manufacturer': 'ê¸°ì•„', 'model_name': 'K5 DL3'},
        ]
        
        # ì‹¤ì œ í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
        # print("í…ŒìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹œì‘...")
        # crawler.crawl_and_save(test_cars)
        
        print("ì—”ì¹´ í¬ë¡¤ëŸ¬ ì¤€ë¹„ ì™„ë£Œ!")
        print("ì‹¤ì œ í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ë ¤ë©´ ì½”ë“œì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.")

    except FileNotFoundError:
        print("ì˜¤ë¥˜: config/scheduler_config.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
