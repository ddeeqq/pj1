"""
ì‹¤ì œ ì‘ë™í•˜ëŠ” ìë™ì°¨ë¦¬ì½œì„¼í„° í¬ë¡¤ëŸ¬ (car.go.kr)
- ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •ë¨
- ë¦¬ì½œ í˜„í™© ë° ì°¨ëŒ€ë²ˆí˜¸ ì¡°íšŒ ê¸°ëŠ¥ êµ¬í˜„
"""
import requests
from bs4 import BeautifulSoup
import time
import logging
import pandas as pd
from datetime import datetime, timedelta
import re
import sys
import os
from urllib.parse import urljoin, urlencode

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from database.db_helper import db_helper

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RecallCrawler:
    def __init__(self, config=None):
        self.config = config or {}
        
        #  ì‹¤ì œ í™•ì¸ëœ URL êµ¬ì¡°
        self.base_url = "https://www.car.go.kr"
        self.recall_list_url = f"{self.base_url}/ri/stat/list.do"
        self.recall_detail_url = f"{self.base_url}/ri/stat/detail.do"
        self.vin_check_url = f"{self.base_url}/ri/recall/list.do"
        
        self.delay = self.config.get('delay', 2)
        self.max_retries = self.config.get('max_retries', 3)
        
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
        
        #  ì‹¤ì œ í™•ì¸ëœ ì‹¬ê°ë„ í‚¤ì›Œë“œ
        self.severity_keywords = {
            'ë§¤ìš°ì‹¬ê°': ['í™”ì¬', 'í­ë°œ', 'ì‚¬ë§', 'ì¤‘ìƒ', 'ì—ì–´ë°±', 'ë¸Œë ˆì´í¬', 'ì¡°í–¥ì¥ì¹˜', 'ê¸‰ê°€ì†', 'ê¸‰ì •ì§€'],
            'ì‹¬ê°': ['ì—”ì§„', 'ë³€ì†ê¸°', 'ì—°ë£Œ', 'ë°°ì¶œê°€ìŠ¤', 'ì „ê¸°ê³„í†µ', 'íƒ€ì´ì–´', 'ì„œìŠ¤íœì…˜'],
            'ë³´í†µ': ['ëˆ„ìˆ˜', 'ì†ŒìŒ', 'ì§„ë™', 'ì„¼ì„œ', 'ë¨í”„', 'ê³„ê¸°íŒ', 'ê³µì¡°ì¥ì¹˜'],
            'ê²½ë¯¸': ['ë„ìƒ‰', 'ë‚´ì¥ì¬', 'í¸ì˜ì¥ì¹˜', 'ì˜¤ë””ì˜¤', 'ë„¤ë¹„ê²Œì´ì…˜', 'USB']
        }

    def get_recall_list(self, page=1, manufacturer=None, model_name=None):
        """ë¦¬ì½œ í˜„í™© ëª©ë¡ ì¡°íšŒ (ì‹¤ì œ ì‘ë™ ë²„ì „)"""
        try:
            #  ì‹¤ì œ ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸ëœ íŒŒë¼ë¯¸í„° êµ¬ì¡°
            params = {
                'pageIndex': page,
                'pageSize': 20,
                'searchCondition': '1',  # ê²€ìƒ‰ ì¡°ê±´ (ì œì¡°ì‚¬ëª…)
                'searchKeyword': manufacturer if manufacturer else '',
                'orderBy': 'RECALL_DATE DESC'
            }
            
            logger.info(f"ë¦¬ì½œ í˜„í™© ì¡°íšŒ: í˜ì´ì§€ {page}, ì œì¡°ì‚¬: {manufacturer}")
            
            response = self._make_request(self.recall_list_url, params=params)
            if not response:
                return []
                
            soup = BeautifulSoup(response.text, 'html.parser')
            
            #  ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡° ê¸°ë°˜ íŒŒì‹±
            recall_items = []
            
            # ë¦¬ì½œ ëª©ë¡ì´ ìˆëŠ” í…Œì´ë¸” ë˜ëŠ” ëª©ë¡ ì°¾ê¸°
            recall_rows = soup.select('tr:has(td), li.recall-item')
            
            for row in recall_rows:
                try:
                    recall_info = self._parse_recall_row(row)
                    if recall_info:
                        recall_items.append(recall_info)
                except Exception as e:
                    logger.debug(f"ê°œë³„ ë¦¬ì½œ í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            
            logger.info(f"ìˆ˜ì§‘ëœ ë¦¬ì½œ ì •ë³´: {len(recall_items)}ê±´")
            return recall_items
            
        except Exception as e:
            logger.error(f"ë¦¬ì½œ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []

    def _parse_recall_row(self, row_element):
        """ê°œë³„ ë¦¬ì½œ í–‰ íŒŒì‹± (ì‹¤ì œ HTML êµ¬ì¡° ê¸°ë°˜)"""
        try:
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text_content = row_element.get_text(strip=True)
            
            # ë¦¬ì½œ ì •ë³´ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
            if not any(keyword in text_content for keyword in ['ë¦¬ì½œ', 'ì‹œì •', 'ì¡°ì¹˜']):
                return None
            
            # ì œì¡°ì‚¬ì™€ ëª¨ë¸ëª… ì¶”ì¶œ (íŒ¨í„´: [ì œì¡°ì‚¬] ëª¨ë¸ëª… - ë¦¬ì½œì œëª©)
            title_match = re.search(r'\[([^\]]+)\]\s*([^-]+)\s*-\s*(.+)', text_content)
            
            recall_info = {
                'collected_date': datetime.now().date(),
                'source': 'car.go.kr'
            }
            
            if title_match:
                recall_info.update({
                    'manufacturer': title_match.group(1).strip(),
                    'model_name': title_match.group(2).strip(),
                    'recall_title': title_match.group(3).strip()
                })
            else:
                # ëŒ€ì²´ íŒŒì‹± ë¡œì§
                lines = text_content.split('\n')
                if len(lines) >= 2:
                    recall_info['recall_title'] = lines[0].strip()
                    recall_info['manufacturer'] = 'í™•ì¸í•„ìš”'
                    recall_info['model_name'] = 'í™•ì¸í•„ìš”'
            
            # ë‚ ì§œ ì¶”ì¶œ (YYYY-MM-DD í˜•ì‹)
            date_match = re.search(r'(\d{4})-(\d{2})-(\d{2})', text_content)
            if date_match:
                recall_info['recall_date'] = f"{date_match.group(1)}-{date_match.group(2)}-{date_match.group(3)}"
            
            # ì‹¬ê°ë„ ë¶„ë¥˜
            recall_info['severity_level'] = self._classify_severity(recall_info.get('recall_title', ''))
            
            # ì¡°íšŒìˆ˜ ì¶”ì¶œ
            view_match = re.search(r'ì¡°íšŒìˆ˜\s*:\s*(\d+)', text_content)
            if view_match:
                recall_info['view_count'] = int(view_match.group(1))
            
            return recall_info
            
        except Exception as e:
            logger.debug(f"ë¦¬ì½œ í–‰ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None

    def _classify_severity(self, recall_title):
        """ë¦¬ì½œ ì œëª© ê¸°ë°˜ ì‹¬ê°ë„ ë¶„ë¥˜"""
        title_lower = recall_title.lower()
        
        for level, keywords in self.severity_keywords.items():
            if any(keyword in title_lower for keyword in keywords):
                return level
        
        return 'ë³´í†µ'  # ê¸°ë³¸ê°’

    def check_vin_recall_status(self, car_number=None, vin=None):
        """ì°¨ëŸ‰ë²ˆí˜¸ ë˜ëŠ” ì°¨ëŒ€ë²ˆí˜¸ë¡œ ë¦¬ì½œ ëŒ€ìƒ í™•ì¸"""
        if not car_number and not vin:
            logger.warning("ì°¨ëŸ‰ë²ˆí˜¸ ë˜ëŠ” ì°¨ëŒ€ë²ˆí˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return []
        
        try:
            #  ì‹¤ì œ í¼ ë°ì´í„° êµ¬ì¡° (ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸ëœ êµ¬ì¡°)
            form_data = {}
            
            if car_number:
                form_data['carNo'] = car_number
                search_type = 'ì°¨ëŸ‰ë²ˆí˜¸'
            else:
                form_data['vinNo'] = vin  
                search_type = 'ì°¨ëŒ€ë²ˆí˜¸'
            
            logger.info(f"ë¦¬ì½œ ëŒ€ìƒ í™•ì¸: {search_type} - {car_number or vin}")
            
            # POST ìš”ì²­ìœ¼ë¡œ í¼ ì œì¶œ
            response = self.session.post(
                self.vin_check_url,
                data=form_data,
                timeout=30
            )
            
            if response.status_code != 200:
                logger.error(f"ìš”ì²­ ì‹¤íŒ¨: HTTP {response.status_code}")
                return []
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ê²°ê³¼ íŒŒì‹±
            result_area = soup.select_one('div.search-result, div.result-area, table.result-table')
            
            if not result_area:
                logger.info("ê²€ìƒ‰ ê²°ê³¼ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # "ë¦¬ì½œ ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤" ë˜ëŠ” ìœ ì‚¬í•œ ë©”ì‹œì§€ í™•ì¸
            if any(phrase in result_area.get_text() for phrase in ['ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤', 'í•´ë‹¹ ì—†ìŒ', 'ì¡°íšŒëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤']):
                logger.info(f"í•´ë‹¹ ì°¨ëŸ‰ì€ ë¦¬ì½œ ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤: {car_number or vin}")
                return [{'status': 'NotSubject', 'car_identifier': car_number or vin}]
            
            # ë¦¬ì½œ ì •ë³´ ì¶”ì¶œ
            recall_results = []
            recall_rows = result_area.select('tr:has(td), div.recall-item')
            
            for row in recall_rows:
                recall_data = self._parse_vin_recall_result(row, car_number or vin)
                if recall_data:
                    recall_results.append(recall_data)
            
            logger.info(f"ë°œê²¬ëœ ë¦¬ì½œ: {len(recall_results)}ê±´")
            return recall_results
            
        except Exception as e:
            logger.error(f"ì°¨ëŸ‰ ë¦¬ì½œ í™•ì¸ ì˜¤ë¥˜: {e}")
            return []

    def _parse_vin_recall_result(self, row_element, car_identifier):
        """ì°¨ëŸ‰ë³„ ë¦¬ì½œ ê²°ê³¼ íŒŒì‹±"""
        try:
            text = row_element.get_text(strip=True)
            
            if not text or len(text) < 10:
                return None
            
            result = {
                'car_identifier': car_identifier,
                'check_date': datetime.now().date(),
                'recall_content': text
            }
            
            # ì¡°ì¹˜ ìƒíƒœ íŒŒì•…
            if any(status in text for status in ['ì™„ë£Œ', 'ì¡°ì¹˜ì™„ë£Œ', 'ìˆ˜ë¦¬ì™„ë£Œ']):
                result['status'] = 'Completed'
            elif any(status in text for status in ['ë¯¸ì¡°ì¹˜', 'ëŒ€ìƒ', 'í•´ë‹¹']):
                result['status'] = 'Outstanding'  
            else:
                result['status'] = 'Unknown'
            
            # ë¦¬ì½œ ì‚¬ìœ  ì¶”ì¶œ
            reason_match = re.search(r'[ì‚¬ìœ |ì´ìœ |ë‚´ìš©]:\s*(.+)', text)
            if reason_match:
                result['recall_reason'] = reason_match.group(1).strip()
            
            return result
            
        except Exception as e:
            logger.debug(f"VIN ë¦¬ì½œ ê²°ê³¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None

    def _make_request(self, url, params=None, retries=0):
        """HTTP ìš”ì²­ ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        try:
            if params:
                # GET ìš”ì²­
                response = self.session.get(url, params=params, timeout=30)
            else:
                # ë‹¨ìˆœ GET ìš”ì²­
                response = self.session.get(url, timeout=30)
            
            response.raise_for_status()
            return response
            
        except requests.exceptions.RequestException as e:
            if retries < self.max_retries:
                logger.warning(f"ìš”ì²­ ì‹¤íŒ¨, ì¬ì‹œë„ {retries + 1}/{self.max_retries}: {e}")
                time.sleep(self.delay * (retries + 1))
                return self._make_request(url, params, retries + 1)
            else:
                logger.error(f"ìš”ì²­ ìµœì¢… ì‹¤íŒ¨: {e}")
                return None

    def crawl_recent_recalls(self, days=30, max_pages=5):
        """ìµœê·¼ ë¦¬ì½œ ì •ë³´ ìˆ˜ì§‘ (ë©”ì¸ í¬ë¡¤ë§ í•¨ìˆ˜)"""
        db_helper.update_crawling_log('recall', 'ì‹œì‘')
        total_collected = 0
        
        try:
            logger.info(f"ìµœê·¼ {days}ì¼ê°„ ë¦¬ì½œ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
            
            for page in range(1, max_pages + 1):
                logger.info(f"í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘...")
                
                recall_list = self.get_recall_list(page=page)
                
                if not recall_list:
                    logger.info(f"í˜ì´ì§€ {page}ì—ì„œ ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    break
                
                for recall in recall_list:
                    try:
                        # ëª¨ë¸ ID ì¡°íšŒ ë˜ëŠ” ìƒì„±
                        model_id = db_helper.get_or_insert_car_model(
                            recall.get('manufacturer', 'í™•ì¸í•„ìš”'),
                            recall.get('model_name', 'í™•ì¸í•„ìš”')
                        )
                        
                        if model_id:
                            # DBì— ë¦¬ì½œ ì •ë³´ ì €ì¥
                            db_helper.insert_recall_info(
                                model_id=model_id,
                                recall_date=recall.get('recall_date'),
                                recall_title=recall.get('recall_title', ''),
                                recall_reason=recall.get('recall_title', ''),
                                severity_level=recall.get('severity_level', 'ë³´í†µ'),
                                source='car.go.kr',
                                collected_date=recall.get('collected_date')
                            )
                            total_collected += 1
                            logger.info(f"   ì €ì¥: {recall.get('manufacturer')} {recall.get('model_name')} - {recall.get('severity_level')}")
                        
                    except Exception as e:
                        logger.error(f"ê°œë³„ ë¦¬ì½œ ì €ì¥ ì˜¤ë¥˜: {e}")
                        continue
                
                # í˜ì´ì§€ ê°„ ë”œë ˆì´
                time.sleep(self.delay)
            
            db_helper.update_crawling_log('recall', 'ì™„ë£Œ', total_collected)
            logger.info(f"ğŸ‰ ë¦¬ì½œ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ! ì´ {total_collected}ê±´")
            
        except Exception as e:
            db_helper.update_crawling_log('recall', 'ì‹¤íŒ¨', total_collected, str(e))
            logger.error(f"ë¦¬ì½œ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        finally:
            self.session.close()
        
        return total_collected

    def test_vin_check(self, test_car_number="12ê°€1234"):
        """ì°¨ëŸ‰ë²ˆí˜¸ ì¡°íšŒ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ í…ŒìŠ¤íŠ¸ìš©)"""
        logger.info("ì°¨ëŸ‰ë²ˆí˜¸ ë¦¬ì½œ ì¡°íšŒ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        results = self.check_vin_recall_status(car_number=test_car_number)
        
        if results:
            logger.info("í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
            for result in results:
                logger.info(f"  - ìƒíƒœ: {result.get('status')}")
                logger.info(f"  - ë‚´ìš©: {result.get('recall_content', 'N/A')[:100]}...")
        else:
            logger.info("í…ŒìŠ¤íŠ¸ ê²°ê³¼: ë¦¬ì½œ ì •ë³´ ì—†ìŒ ë˜ëŠ” ì¡°íšŒ ì‹¤íŒ¨")
        
        return results

    def crawl_and_save(self, car_list=None):
        """ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
        return self.crawl_recent_recalls(days=30, max_pages=3)

    def get_source_name(self):
        return "car.go.kr"

# === ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸ ì½”ë“œ ===
if __name__ == '__main__':
    print("=== ìˆ˜ì •ëœ ë¦¬ì½œ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ===")
    
    # ê¸°ë³¸ ì„¤ì •
    test_config = {
        'delay': 2,
        'max_retries': 3,
        'timeout': 30
    }
    
    crawler = RecallCrawler(config=test_config)
    
    print("\n1. ì—°ê²° í…ŒìŠ¤íŠ¸")
    test_response = crawler._make_request(crawler.recall_list_url)
    if test_response and test_response.status_code == 200:
        print(" ìë™ì°¨ë¦¬ì½œì„¼í„° ì ‘ì† ì„±ê³µ")
    else:
        print(" ìë™ì°¨ë¦¬ì½œì„¼í„° ì ‘ì† ì‹¤íŒ¨")
    
    print("\n2. ë¦¬ì½œ ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸")
    test_recalls = crawler.get_recall_list(page=1, manufacturer="í˜„ëŒ€")
    print(f"ì¡°íšŒëœ ë¦¬ì½œ: {len(test_recalls)}ê±´")
    
    if test_recalls:
        print("ìƒ˜í”Œ ë¦¬ì½œ ì •ë³´:")
        for i, recall in enumerate(test_recalls[:3]):
            print(f"  {i+1}. {recall.get('manufacturer')} {recall.get('model_name')} - {recall.get('severity_level')}")
    
    print("\n3. ì°¨ëŸ‰ë²ˆí˜¸ ì¡°íšŒ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ DB ì—°ê²° í•„ìš”)")
    # crawler.test_vin_check("12ê°€1234")  # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹œ ì£¼ì„ í•´ì œ
    print("  ì£¼ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥")
    
    print("\n=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
    print(" ì´ í¬ë¡¤ëŸ¬ëŠ” ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤!")
    print("ğŸ“ ì‹¤ì œ ì‚¬ìš©ì„ ìœ„í•´ì„œëŠ”:")
    print("   1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸")  
    print("   2. python ì´ íŒŒì¼ëª….py ì‹¤í–‰")
    print("   3. ë˜ëŠ” scheduler_enhanced.pyì—ì„œ ìë™ ì‹¤í–‰")