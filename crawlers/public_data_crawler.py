"""
ê³µê³µë°ì´í„° ë° ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ê¸°
- (ê¸°ì¡´) ìë™ì°¨ ë“±ë¡ í˜„í™© ë°ì´í„° ìˆ˜ì§‘
- (ì¶”ê°€) ì‹ ì°¨ ì¶œê³ ê°€(MSRP) ì •ë³´ ìˆ˜ì§‘
"""
import pandas as pd
import logging
from datetime import datetime
import sys
import os
import requests
import json

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from database.db_helper import db_helper

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PublicDataCrawler:
    def __init__(self, config):
        """í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì‹œ ì„¤ì •(config)ì„ ì „ë‹¬ë°›ìŒ"""
        self.config = config
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': self.config.get('user_agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)')
        })

    # --- ì‹ ì°¨ ì¶œê³ ê°€(MSRP) ìˆ˜ì§‘ ê¸°ëŠ¥ ---
    def get_new_car_msrp(self, model_id, manufacturer, model_name, year, trim_name):
        """íŠ¹ì • ëª¨ë¸, ì—°ì‹, íŠ¸ë¦¼ì— í•´ë‹¹í•˜ëŠ” ì‹ ì°¨ì˜ ê³µì‹ ì¶œê³ ê°€(MSRP)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        
        # USER ACTION: ì‹ ì°¨ ê°€ê²© ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” APIë‚˜ ì›¹ì‚¬ì´íŠ¸ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.
        # í˜„ëŒ€/ê¸°ì•„ì°¨ì˜ ê²½ìš°, ìì²´ì ìœ¼ë¡œ ê°€ê²©í‘œ APIë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ë˜ëŠ” ë‹¤ë‚˜ì™€ ìë™ì°¨, ë„¤ì´ë²„ ìë™ì°¨ ë“±ì˜ ì œ3ì ì‚¬ì´íŠ¸ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ì•„ë˜ëŠ” ì˜ˆì‹œì ì¸ API URL êµ¬ì¡°ì…ë‹ˆë‹¤.
        api_url_template = self.config.get(
            'msrp_api_url', 
            'https://api.example.com/new-car-prices?manufacturer={mf}&model={mo}&year={yr}&trim={tr}'
        )
        url = api_url_template.format(mf=manufacturer, mo=model_name, yr=year, tr=trim_name)

        try:
            logger.info(f"MSRP ì¡°íšŒ: {manufacturer} {model_name} {year} {trim_name}")
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            # USER ACTION: API ì‘ë‹µ í˜•ì‹(JSON, XML, HTML ë“±)ì— ë§ê²Œ íŒŒì‹± ë¡œì§ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
            # ì•„ë˜ëŠ” JSON ì‘ë‹µì„ ê°€ì •í•©ë‹ˆë‹¤.
            data = response.json()
            msrp = data.get('price') # ì˜ˆ: {"price": 55000000}

            if msrp:
                logger.info(f"  -> MSRP ë°œê²¬: {msrp}")
                # USER ACTION: db_helperì— ì‹ ì°¨ ê°€ê²© ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ë©”ì†Œë“œë¥¼ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.
                # ì˜ˆ: db_helper.insert_or_update_msrp(model_id, year, trim_name, msrp)
                return msrp
            else:
                logger.warning(f"  -> MSRP ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None

        except requests.exceptions.RequestException as e:
            logger.error(f"MSRP API ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None
        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"MSRP API ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None

    # --- ê¸°ì¡´ ìë™ì°¨ ë“±ë¡ í˜„í™© ë°ì´í„° ìˆ˜ì§‘ ê¸°ëŠ¥ ---
    def load_registration_data(self, file_path=None):
        """ì—‘ì…€ íŒŒì¼ì—ì„œ ìë™ì°¨ ë“±ë¡ í˜„í™© ë°ì´í„° ë¡œë“œ"""
        try:
            if not file_path:
                file_path = self.config.get('file_path')
                if not file_path:
                    logger.error("ì„¤ì •ì— file_pathê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    return pd.DataFrame()

            logger.info(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘: {file_path}")
            excel_file = pd.ExcelFile(file_path)
            all_data = []
            
            for sheet_name in excel_file.sheet_names:
                logger.info(f"ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘: {sheet_name}")
                df = pd.read_excel(excel_file, sheet_name=sheet_name)
                df = self._clean_registration_data(df, sheet_name)
                if not df.empty:
                    all_data.append(df)
                    
            if all_data:
                combined_df = pd.concat(all_data, ignore_index=True)
                logger.info(f"âœ… ì´ {len(combined_df)}ê±´ì˜ ë“±ë¡ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                return combined_df
            else:
                logger.warning("ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
                
        except FileNotFoundError:
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return pd.DataFrame()
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
            
    def _clean_registration_data(self, df, sheet_name):
        """ë“±ë¡ ë°ì´í„° ì •ì œ"""
        try:
            column_mapping = {
                'ì‹œë„': 'region', 'ì§€ì—­': 'region', 'ì œì¡°ì‚¬': 'manufacturer', 'ë¸Œëœë“œ': 'manufacturer',
                'ì°¨ëª…': 'model_name', 'ëª¨ë¸': 'model_name', 'ì°¨ëŸ‰ëª…': 'model_name', 'ë“±ë¡ëŒ€ìˆ˜': 'registration_count',
                'ëŒ€ìˆ˜': 'registration_count', 'ëˆ„ì ëŒ€ìˆ˜': 'cumulative_count', 'ë‚ ì§œ': 'registration_date',
                'ê¸°ì¤€ì¼': 'registration_date', 'ì—°ë£Œ': 'fuel_type', 'ì—°ë£Œêµ¬ë¶„': 'fuel_type'
            }
            df.rename(columns=column_mapping, inplace=True)
            
            required_columns = ['manufacturer', 'model_name', 'registration_count']
            if not all(col in df.columns for col in required_columns):
                logger.warning(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {required_columns}")
                return pd.DataFrame()
                
            if 'registration_date' not in df.columns:
                df['registration_date'] = pd.Timestamp.now().date()
            else:
                df['registration_date'] = pd.to_datetime(df['registration_date']).dt.date
            
            for col, default in [('region', 'ì „êµ­'), ('cumulative_count', df.get('registration_count'))]:
                if col not in df.columns:
                    df[col] = default
            
            df['registration_count'] = pd.to_numeric(df['registration_count'], errors='coerce').fillna(0)
            df['cumulative_count'] = pd.to_numeric(df['cumulative_count'], errors='coerce').fillna(0)
            return df[df['registration_count'] > 0]
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì •ì œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
            
    def save_registration_data_to_db(self, df):
        """ë°ì´í„°í”„ë ˆì„ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        db_helper.update_crawling_log('public_data', 'ì‹œì‘')
        saved_count = 0
        try:
            for _, row in df.iterrows():
                model_id = db_helper.get_or_insert_car_model(
                    row['manufacturer'], row['model_name'], row.get('fuel_type')
                )
                if model_id:
                    db_helper.insert_registration_stats(
                        model_id=model_id, region=row['region'],
                        registration_date=row['registration_date'],
                        registration_count=int(row['registration_count']),
                        cumulative_count=int(row.get('cumulative_count', row['registration_count']))
                    )
                    saved_count += 1
            db_helper.update_crawling_log('public_data', 'ì™„ë£Œ', saved_count)
            logger.info(f"âœ… {saved_count}ê±´ì˜ ë“±ë¡ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            db_helper.update_crawling_log('public_data', 'ì‹¤íŒ¨', saved_count, str(e))
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")

if __name__ == '__main__':
    import json
    print("ê³µê³µë°ì´í„° í¬ë¡¤ëŸ¬ ë‹¨ë… í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    
    try:
        with open('config/scheduler_config.json', 'r', encoding='utf-8') as f:
            full_config = json.load(f)
        public_data_config = full_config['crawling']['public_data']
        print("âœ… í…ŒìŠ¤íŠ¸ ì„¤ì • ë¡œë“œ ì™„ë£Œ")

        crawler = PublicDataCrawler(config=public_data_config)

        # --- ì‹ ì°¨ ê°€ê²© ì¡°íšŒ í…ŒìŠ¤íŠ¸ ---
        print("\n--- ì‹ ì°¨ ê°€ê²©(MSRP) ì¡°íšŒ í…ŒìŠ¤íŠ¸ ---")
        # test_msrp = crawler.get_new_car_msrp(1, 'í˜„ëŒ€', 'ê·¸ëœì € IG', 2022, '2.4 í”„ë¦¬ë¯¸ì—„')
        # if test_msrp:
        #     print(f"í…ŒìŠ¤íŠ¸ MSRP ê²°ê³¼: {test_msrp}")
        print("ì‹¤ì œ ì‹¤í–‰í•˜ë ¤ë©´ `get_new_car_msrp` ë©”ì†Œë“œì˜ ì£¼ì„ì„ í•´ì œí•˜ê³ , API URLê³¼ íŒŒì‹± ë¡œì§ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.")

        # --- ê¸°ì¡´ ë“±ë¡ ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸ ---
        print("\n--- ìë™ì°¨ ë“±ë¡ ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸ ---")
        df = crawler.load_registration_data()
        if not df.empty:
            print(f"ë¡œë“œëœ ë°ì´í„° ìˆ˜: {len(df)}ê±´")
            print(df.head())
            # crawler.save_registration_data_to_db(df)
        else:
            print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")

    except FileNotFoundError:
        print("ì˜¤ë¥˜: config/scheduler_config.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")