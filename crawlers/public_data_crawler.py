"""
ê³µê³µë°ì´í„° í¬í„¸ì—ì„œ ìë™ì°¨ ë“±ë¡ í˜„í™© ë°ì´í„° ìˆ˜ì§‘
"""
import pandas as pd
import logging
from datetime import datetime
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from database.db_helper import db_helper

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PublicDataCrawler:
    def __init__(self, config):
        """í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì‹œ ì„¤ì •(config)ì„ ì „ë‹¬ë°›ìŒ"""
        self.config = config
        
    def load_registration_data(self, file_path=None):
        """ì—‘ì…€ íŒŒì¼ì—ì„œ ìë™ì°¨ ë“±ë¡ í˜„í™© ë°ì´í„° ë¡œë“œ"""
        try:
            # íŒŒì¼ ê²½ë¡œê°€ ì—†ìœ¼ë©´ ì„¤ì •ì˜ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
            if not file_path:
                file_path = self.config.get('file_path')
                if not file_path:
                    logger.error("ì„¤ì •ì— file_pathê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    return pd.DataFrame()

            logger.info(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘: {file_path}")
            excel_file = pd.ExcelFile(file_path)
            all_data = []
            
            for sheet_name in excel_file.sheet_names:
                logger.info(f"ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘: {sheet_name}")
                df = pd.read_excel(excel_file, sheet_name=sheet_name)
                df = self._clean_registration_data(df, sheet_name)
                if not df.empty:
                    all_data.append(df)
                    
            if all_data:
                combined_df = pd.concat(all_data, ignore_index=True)
                logger.info(f"âœ… ì´ {len(combined_df)}ê±´ì˜ ë“±ë¡ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                return combined_df
            else:
                logger.warning("ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
                
        except FileNotFoundError:
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            logger.info("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            return self._create_sample_registration_data()
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
            
    def _clean_registration_data(self, df, sheet_name):
        """ë“±ë¡ ë°ì´í„° ì •ì œ"""
        try:
            column_mapping = {
                'ì‹œë„': 'region', 'ì§€ì—­': 'region', 'ì œì¡°ì‚¬': 'manufacturer', 'ë¸Œëœë“œ': 'manufacturer',
                'ì°¨ëª…': 'model_name', 'ëª¨ë¸': 'model_name', 'ì°¨ëŸ‰ëª…': 'model_name', 'ë“±ë¡ëŒ€ìˆ˜': 'registration_count',
                'ëŒ€ìˆ˜': 'registration_count', 'ëˆ„ì ëŒ€ìˆ˜': 'cumulative_count', 'ë‚ ì§œ': 'registration_date',
                'ê¸°ì¤€ì¼': 'registration_date', 'ì—°ë£Œ': 'fuel_type', 'ì—°ë£Œêµ¬ë¶„': 'fuel_type'
            }
            df.rename(columns=column_mapping, inplace=True)
            
            required_columns = ['manufacturer', 'model_name', 'registration_count']
            if not all(col in df.columns for col in required_columns):
                logger.warning(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {required_columns}")
                return pd.DataFrame()
                
            if 'registration_date' not in df.columns:
                df['registration_date'] = pd.Timestamp.now().date()
            else:
                df['registration_date'] = pd.to_datetime(df['registration_date']).dt.date
            
            for col, default in [('region', 'ì „êµ­'), ('cumulative_count', df.get('registration_count'))]:
                if col not in df.columns:
                    df[col] = default
            
            df['registration_count'] = pd.to_numeric(df['registration_count'], errors='coerce').fillna(0)
            df['cumulative_count'] = pd.to_numeric(df['cumulative_count'], errors='coerce').fillna(0)
            return df[df['registration_count'] > 0]
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì •ì œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
            
    def _create_sample_registration_data(self):
        """ìƒ˜í”Œ ë“±ë¡ ë°ì´í„° ìƒì„±"""
        sample_data = {
            'manufacturer': ['í˜„ëŒ€', 'ê¸°ì•„', 'ì œë„¤ì‹œìŠ¤'] * 2,
            'model_name': ['ê·¸ëœì €', 'ì˜ë‚˜íƒ€', 'ì•„ë°˜ë–¼', 'K5', 'K8', 'G80'],
            'region': ['ì„œìš¸', 'ê²½ê¸°', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼'],
            'registration_count': [1250, 2340, 890, 1560, 780, 450],
            'registration_date': [datetime.now().date()] * 6
        }
        df = pd.DataFrame(sample_data)
        logger.info("âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        return df
        
    def save_to_database(self, df):
        """ë°ì´í„°í”„ë ˆì„ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        db_helper.update_crawling_log('public_data', 'ì‹œì‘')
        saved_count = 0
        try:
            for _, row in df.iterrows():
                model_id = db_helper.get_or_insert_car_model(
                    row['manufacturer'], row['model_name'], row.get('fuel_type')
                )
                if model_id:
                    db_helper.insert_registration_stats(
                        model_id=model_id, region=row['region'],
                        registration_date=row['registration_date'],
                        registration_count=int(row['registration_count']),
                        cumulative_count=int(row.get('cumulative_count', row['registration_count']))
                    )
                    saved_count += 1
            db_helper.update_crawling_log('public_data', 'ì™„ë£Œ', saved_count)
            logger.info(f"âœ… {saved_count}ê±´ì˜ ë“±ë¡ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            db_helper.update_crawling_log('public_data', 'ì‹¤íŒ¨', saved_count, str(e))
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")

if __name__ == '__main__':
    import json
    print("ê³µê³µë°ì´í„° í¬ë¡¤ëŸ¬ ë‹¨ë… í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    
    try:
        with open('config/scheduler_config.json', 'r', encoding='utf-8') as f:
            full_config = json.load(f)
        public_data_config = full_config['crawling']['public_data']
        print("âœ… í…ŒìŠ¤íŠ¸ ì„¤ì • ë¡œë“œ ì™„ë£Œ")

        crawler = PublicDataCrawler(config=public_data_config)
        df = crawler.load_registration_data()
        
        if not df.empty:
            print(f"ë¡œë“œëœ ë°ì´í„° ìˆ˜: {len(df)}ê±´")
            print("\në°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
            print(df.head())
            # crawler.save_to_database(df)
        else:
            print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")

    except FileNotFoundError:
        print("ì˜¤ë¥˜: config/scheduler_config.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
